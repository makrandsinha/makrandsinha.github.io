<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>

<title>Makrand Sinha</title>
<style type="text/css" media="all">@import "global.css";</style>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>
<script src="abstract-click.js" type="text/javascript"></script>
<meta name="robots" content="index" />
<meta name="googlebot" content="index" />
</head><body>

<div id="container">

<div id="right">
<img alt="Makrand" width=200px src="image.jpg">
</div>

<div id="left">
<h1>Makrand Sinha</h1>

<p>
Networks & Optimization Group<br>
Centrum Wiskunde & Informatika<br>
Science Park 123<br>
1098 XG Amsterdam<br>
NETHERLANDS<br>
</p>

<p>
<b>Email:</b> Makrand.Sinha then the at sign followed by cwi nl separated by dots 
</p>

<div id="main">

<h2>About Me</h2>
<p class="about">I am a postdoctoral reseacher in the <a href ="https://www.cwi.nl/research/groups/networks-and-optimization">Networks and Optimization</a> group at <a href="https://www.cwi.nl/">CWI</a> in Amsterdam. My primary research interests lie in Communication Complexity, Lower Bounds for Linear and Semidefinite Programs, and Convex Geometry and Optimization.</p>

<p class="about">I received my PhD in August 2018 from the <a href="http://www.cs.washington.edu/">Paul G. Allen School of Computer Science & Engineering</a> at <a href="http://www.washington.edu">University of Washington</a> in Seattle under the guidance of <a href="http://www.cs.washington.edu/homes/anuprao/">Anup Rao</a>.</p>

<p class="about">Previously I completed my Masters at the <a href="http://www.inf.ethz.ch/">Computer Science Department</a>  in <a href="http://www.ethz.ch/index_EN">ETH Z&uuml;rich</a> advised by Thomas Holenstein. Before that I did a Bachelor's in Computer Science (2005-2009) at <a href="http://www.cse.iitk.ac.in/">IIT Kanpur</a>.</p>

<p class="about">You can find my curriculum vitae here: <a href="./makrand_cv.pdf">CV [PDF]</a>

<hr>
<h3>Announcements</h3>
<ul>
    <li>I ran a <a href="https://makrandsinha.github.io/reading/">reading group</a> on Random Matrices, Matrix Concentration and related topics in Fall '19.</li>

    <li>Together with <a href="https://ankit-garg-6.github.io">Ankit Garg</a>, <a href="https://raghumeka.github.io/">Raghu Meka</a> and <a href="https://www.cs.toronto.edu/~toni/">Tonian Pitassi</a>, I organized a workshop on extension complexity and lifting theorems at <strong>FSTTCS '19</strong>. See <a href="https://ankit-garg-6.github.io/fsttcs19lifting/">here</a> for details.</li>
</ul>
<hr>

</div>

<div id="pubs">
<h2>Publications</h2>
<ul id="pubs">

<li>
<span class="papertitle">Online Discrepancy Minimization for Stochastic Arrivals</span><br>
<a href="https://www.win.tue.nl/~nikhil/">Nikhil Bansal</a>, <a href="https://jhtdavid96.wixsite.com/jianghaotian">Haotian Jiang</a>,  <a href="https://hackmd.io/@raghum/index">Raghu Meka</a>, <a href="https://www.cs.princeton.edu/~singla/">Sahil Singla</a> and Makrand Sinha<br>
Manuscript. </li>
[<a href="https://arxiv.org/abs/2007.10622">arXiv</a>] <a href="#" onclick="toggle('onlinediscban');return false;" class="plus" id="onlinediscban-plus">[Abstract +]</a> <div id="onlinediscban" class="abstract">
    <p> In the stochastic online vector balancing problem, vectors \(v_1,v_2,\ldots,v_T\) chosen independently from an arbitrary distribution in \(\BR^n\) arrive one-by-one and must be immediately given a \(\pm\) sign. The goal is to keep the norm of the discrepancy vector, i.e., the signed prefix-sum, as small as possible for a given target norm.</p>

    <p> We consider some of the most well-known problems in discrepancy theory in the above online stochastic setting, and give algorithms that match the known offline bounds up to \(\mathrm{polylog}(nT)\) factors. This substantially generalizes and improves upon the previous results of Bansal, Jiang, Singla,  and Sinha (STOC' 20). In particular, for the Koml\'{o}s problem where \(\|v_t\|_2\leq 1\) for each \(t\), our algorithm achieves \(\widetilde{O}(1)\) discrepancy with high probability, improving upon the previous \(\widetilde{O}(n^{3/2})\) bound. For Tusn\'{a}dy's problem of minimizing the discrepancy of axis-aligned boxes, we obtain an \(O(\log^{d+4} T)\) bound for arbitrary distribution over points. Previous techniques only worked for product distributions and gave a weaker \(O(\log^{2d+1} T)\) bound. We also consider the Banaszczyk setting, where given a symmetric convex body \(K\) with Gaussian measure at least \(1/2\), our algorithm achieves \(\widetilde{O}(1)\) discrepancy with respect to the norm given by \(K\) for input distributions with sub-exponential tails.</p>

    <p>  Our results are based on a new potential function approach. Previous techniques consider a potential that penalizes large discrepancy, and greedily chooses the next color to minimize the increase in potential. Our key idea is to introduce a potential that also enforces constraints on how the discrepancy vector evolves, allowing us to maintain certain anti-concentration properties. We believe that our techniques to control the evolution of states could find other applications in  stochastic processes and online algorithms. For the Banaszczyk setting, we further enhance this potential by combining it with ideas from generic chaining. Finally, we also extend these results to the setting of online multi-color discrepancy.</p>
</div>
<noscript>
	<div class="nsabstract">
  <p> In the stochastic online vector balancing problem, vectors \(v_1,v_2,\ldots,v_T\) chosen independently from an arbitrary distribution in \(\BR^n\) arrive one-by-one and must be immediately given a \(\pm\) sign. The goal is to keep the norm of the discrepancy vector, i.e., the signed prefix-sum, as small as possible for a given target norm.</p>

    <p> We consider some of the most well-known problems in discrepancy theory in the above online stochastic setting, and give algorithms that match the known offline bounds up to \(\mathrm{polylog}(nT)\) factors. This substantially generalizes and improves upon the previous results of Bansal, Jiang, Singla,  and Sinha (STOC' 20). In particular, for the Koml\'{o}s problem where \(\|v_t\|_2\leq 1\) for each \(t\), our algorithm achieves \(\widetilde{O}(1)\) discrepancy with high probability, improving upon the previous \(\widetilde{O}(n^{3/2})\) bound. For Tusn\'{a}dy's problem of minimizing the discrepancy of axis-aligned boxes, we obtain an \(O(\log^{d+4} T)\) bound for arbitrary distribution over points. Previous techniques only worked for product distributions and gave a weaker \(O(\log^{2d+1} T)\) bound. We also consider the Banaszczyk setting, where given a symmetric convex body \(K\) with Gaussian measure at least \(1/2\), our algorithm achieves \(\widetilde{O}(1)\) discrepancy with respect to the norm given by \(K\) for input distributions with sub-exponential tails.</p>

    <p>  Our results are based on a new potential function approach. Previous techniques consider a potential that penalizes large discrepancy, and greedily chooses the next color to minimize the increase in potential. Our key idea is to introduce a potential that also enforces constraints on how the discrepancy vector evolves, allowing us to maintain certain anti-concentration properties. We believe that our techniques to control the evolution of states could find other applications in  stochastic processes and online algorithms. For the Banaszczyk setting, we further enhance this potential by combining it with ideas from generic chaining. Finally, we also extend these results to the setting of online multi-color discrepancy.</p>
    </div></noscript>

<li>
<span class="papertitle">Online Vector Balancing and Geometric Discrepancy</span><br>
<a href="https://www.win.tue.nl/~nikhil/">Nikhil Bansal</a>, <a href="https://jhtdavid96.wixsite.com/jianghaotian">Haotian Jiang</a>, <a href="https://www.cs.princeton.edu/~singla/">Sahil Singla</a> and Makrand Sinha<br>
To appear in <strong>STOC '20</strong>. </li>
[<a href="https://arxiv.org/abs/1912.03350">arXiv</a>] <a href="#" onclick="toggle('onlinedisc');return false;" class="plus" id="onlinedisc-plus">[Abstract +]</a> <div id="onlinedisc" class="abstract"> 
	<p> We consider an {online vector balancing} question where \(T\) vectors, chosen from an {arbitrary} distribution over \([-1,1]^n\), arrive one-by-one and must be immediately given a \(\pm\) sign. The goal is to keep the {discrepancy}---the \(\ell_{\infty}\)-norm of any signed prefix-sum---as small as possible. A concrete example of this question is the {online interval discrepancy} problem where \(T\) points are sampled one-by-one uniformly in the unit interval \([0,1]\), and the goal is to immediately color them \(\pm\) such that every sub-interval remains always nearly balanced. As random coloring incurs \(\Omega(T^{1/2})\) discrepancy, while the offline bounds are \(\Theta((n\log T)^{1/2})\) for vector balancing and \(1\) for interval balancing, a natural question is whether one can (nearly) match the offline bounds in the online setting for these problems. One must utilize the stochasticity as in the worst-case scenario it is known that discrepancy is \(\Omega(T^{1/2})\) for any online algorithm.</p>

    <p> In a special case of online vector balancing, Bansal and Spencer (arXiv '19)} recently show an \(O(\sqrt{n}\log T)\) bound when each coordinate is <em>independently</em> chosen. When there are <em>dependencies</em> among the coordinates, as in the interval discrepancy problem, the problem becomes much more challenging, as evidenced by a recent work of Jiang, Kulkarni, and Singla (arXiv '19) that gives a non-trivial \(O(T^{1/\log\log T})\) bound for  online interval discrepancy. Although this beats random coloring, it is still far from the offline bound.</p>
    <p>
    In this work, we introduce a new framework that allows us to handle online vector balancing even when the input distribution has {dependencies} across coordinates. In particular, this lets us obtain a \(\mathrm{poly}(n, \log T)\) bound for online vector balancing under arbitrary input distributions, and a \(\mathrm{polylog} (T)\) bound for online interval discrepancy. Our framework is powerful enough to capture other well-studied geometric discrepancy problems; e.g., we obtain a \(\mathrm{poly}(\log^d (T))\) bound for the online \(d\)-dimensional Tus\'nady's problem. All our bounds are tight up to polynomial factors.</p>
    <p>
    A key new technical ingredient in our work is an <em>anti-concentration</em> inequality for sums of pairwise uncorrelated random variables, which might also be of independent interest.
    </p>

</div>
<noscript>
	<div class="nsabstract">
	<p> We consider an {online vector balancing} question where \(T\) vectors, chosen from an {arbitrary} distribution over \([-1,1]^n\), arrive one-by-one and must be immediately given a \(\pm\) sign. The goal is to keep the {discrepancy}---the \(\ell_{\infty}\)-norm of any signed prefix-sum---as small as possible. A concrete example of this question is the {online interval discrepancy} problem where \(T\) points are sampled one-by-one uniformly in the unit interval \([0,1]\), and the goal is to immediately color them \(\pm\) such that every sub-interval remains always nearly balanced. As random coloring incurs \(\Omega(T^{1/2})\) discrepancy, while the offline bounds are \(\Theta((n\log T)^{1/2})\) for vector balancing and \(1\) for interval balancing, a natural question is whether one can (nearly) match the offline bounds in the online setting for these problems. One must utilize the stochasticity as in the worst-case scenario it is known that discrepancy is \(\Omega(T^{1/2})\) for any online algorithm.</p>

    <p> In a special case of online vector balancing, Bansal and Spencer (arXiv '19)} recently show an \(O(\sqrt{n}\log T)\) bound when each coordinate is <em>independently</em> chosen. When there are <em>dependencies</em> among the coordinates, as in the interval discrepancy problem, the problem becomes much more challenging, as evidenced by a recent work of Jiang, Kulkarni, and Singla (arXiv '19) that gives a non-trivial \(O(T^{1/\log\log T})\) bound for  online interval discrepancy. Although this beats random coloring, it is still far from the offline bound.</p>
    <p>
    In this work, we introduce a new framework that allows us to handle online vector balancing even when the input distribution has {dependencies} across coordinates. In particular, this lets us obtain a \(\poly(n, \log T)\) bound for online vector balancing under arbitrary input distributions, and a \(\polylog (T)\) bound for online interval discrepancy. Our framework is powerful enough to capture other well-studied geometric discrepancy problems; e.g., we obtain a \(\poly(\log^d (T))\) bound for the online \(d\)-dimensional Tus\'nady's problem. All our bounds are tight up to polynomial factors.</p>
    <p>
    A key new technical ingredient in our work is an <em>anti-concentration</em> inequality for sums of pairwise uncorrelated random variables, which might also be of independent interest.
    </p>
    </div></noscript>

<br>

<li>
<span class="papertitle">Exponential Separation between Quantum Communication and Logarithm of Approximate Rank</span><br>
Makrand Sinha and <a href="https://homepages.cwi.nl/~rdewolf/">Ronald de Wolf</a><br>
Appeared in <strong>FOCS '19</strong>. Accepted at <strong>QIP '20</strong> (as part of a joint submission).</li>
[<a href="https://arxiv.org/abs/1811.10090">arXiv</a>] [<a href="https://eccc.weizmann.ac.il/report/2018/204/">ECCC</a>]  <a href="#" onclick="toggle('qlogrank');return false;" class="plus" id="qlogrank-plus">[Abstract +]</a> <div id="qlogrank" class="abstract"> 
	<p>
    Chattopadhyay, Mande and Sherif (ECCC 2018) recently exhibited a total Boolean function, the <em>sink</em> function, that has polynomial approximate rank and polynomial randomized communication complexity. This gives an exponential separation between randomized communication complexity and logarithm of the approximate rank, refuting the log-approximate-rank conjecture. We show that even the <em>quantum</em> communication complexity of the sink function is polynomial, thus also refuting the quantum log-approximate-rank conjecture.</p>

    <p> Our lower bound is based on the fooling distribution method introduced by Rao and Sinha (ECCC 2015) for the classical case and extended by Anshu, Touchette, Yao and Yu (STOC 2017) for the quantum case. We also give a new proof of the classical lower bound using the fooling distribution method. 	</p>

</div>
<noscript>
	<div class="nsabstract">
<p>
Chattopadhyay, Mande and Sherif (ECCC 2018) recently exhibited a total Boolean function, the <em>sink</em> function, that has polynomial approximate rank and polynomial randomized communication complexity. This gives an exponential separation between randomized communication complexity and logarithm of the approximate rank, refuting the log-approximate-rank conjecture. We show that even the <em>quantum</em> communication complexity of the sink function is polynomial, thus also refuting the quantum log-approximate-rank conjecture.</p>

<p> Our lower bound is based on the fooling distribution method introduced by Rao and Sinha (ECCC 2015) for the classical case and extended by Anshu, Touchette, Yao and Yu (STOC 2017) for the quantum case. We also give a new proof of the classical lower bound using the fooling distribution method.</p>
</div></noscript>

<br>


<li>
<span class="papertitle">Simplified Separation of Information and Communication</span><br>
<a href="http://www.cs.washington.edu/homes/anuprao/">Anup Rao</a> and Makrand Sinha<br>
Appeared in <strong>Theory of Computing</strong>, Volume 14, Article 20, pp. 1-29, December 2018.</li>
[<a href="http://www.theoryofcomputing.org/articles/v014a020/">Journal</a>] [<a href="http://eccc.hpi-web.de/report/2015/057/">ECCC</a>] <a href="#" onclick="toggle('separation');return false;" class="plus" id="separation-plus">[Abstract +]</a> <div id="separation" class="abstract"> 
	<p>
    We give an example of a boolean function whose information complexity is exponentially smaller than its communication complexity. This was first proven recently by Ganor, Kol and Raz (J. ACM 2016) and our work gives a simpler proof of the same result. In the course of this simplification, we make several new contributions: we introduce a new communication lower bound technique, the notion of a <em>fooling distribution</em>, which allows us to separate information and communication complexity, and we also give a more direct proof for the information complexity upper bound.</p> 

    <p> We also prove a generalization of Shearer's Lemma that may be of independent interest. A version of Shearer's original lemma bounds the expected mutual information of a subset of random variables with another random variable, when the subset is chosen independently of all the random variables that are involved. Our generalization allows some dependence between the random subset and the random variables involved, and still gives us similar bounds with an appropriate error term.
</p>

</div>
<noscript>
	<div class="nsabstract">
<p>
We give an example of a boolean function whose information complexity is exponentially smaller than its communication complexity. This was first proven recently by Ganor, Kol and Raz (J. ACM 2016) and our work gives a simpler proof of the same result. In the course of this simplification, we make several new contributions: we introduce a new communication lower bound technique, the notion of a <em>fooling distribution</em>, which allows us to separate information and communication complexity, and we also give a more direct proof for the information complexity upper bound. We also prove a generalization of Shearer's Lemma that may be of independent interest.
</p>
</div></noscript>

<br>

<li>
<span class="papertitle">Edge Estimation with Independent Set Oracles</span><br>
<a href="https://www.cs.washington.edu/people/faculty/beame/">Paul Beame</a>, <a href="http://sarielhp.org/">Sariel Har-Peled</a>, <a href="https://homes.cs.washington.edu/~sivanr/">Sivaramakrishnan Natarajan Ramamoorthy</a>, <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a> and Makrand Sinha<br>
To appear in Proceedings of the 9th Innovations in Theoretical Computer Science<br><strong>(ITCS '18)</strong></li>
[<a href="http://arxiv.org/abs/1711.07567">arXiv</a>] <a href="#" onclick="toggle('indset');return false;" class="plus" id="indset-plus">[Abstract +]</a> <div id="indset" class="abstract"> 
	<p>
	We study the problem of estimating the number of edges in a graph with access to only an independent set oracle. Independent set queries draw motivation from group testing and have applications to the complexity of decision versus counting problems. We give two algorithms to estimate the number of edges in an \(n\)-vertex graph: one that uses only \(\mathrm{polylog}(n)\) bipartite independent set queries, and another one that uses \({n}^{2/3} \cdot \mathrm{polylog}(n)\) independent set queries.
	</p>

</div>
<noscript>
	<div class="nsabstract">
<p>
	We study the problem of estimating the number of edges in a graph with access to only an independent set oracle. Independent set queries draw motivation from group testing and have applications to the complexity of decision versus counting problems. We give two algorithms to estimate the number of edges in an \(n\)-vertex graph: one that uses only \(\mathrm{polylog}(n)\) bipartite independent set queries, and another one that uses \({n}^{2/3} \cdot \mathrm{polylog}(n)\) independent set queries.
</p>
</div></noscript>
<br>


<li>
<span class="papertitle">Lower Bounds for Approximating the Matching Polytope</span><br>
Makrand Sinha<br>
To appear in Proceedings of the 29th Annual ACM-SIAM Symposium on Discrete Algorithms <br><strong>(SODA '18)</strong></li>
[<a href="https://arxiv.org/abs/1711.10145">arXiv</a>] [<a href="https://eccc.weizmann.ac.il/report/2017/185/">ECCC</a>] <a href="#" onclick="toggle('matching');return false;" class="plus" id="matching-plus">[Abstract +]</a> <div id="matching" class="abstract"> 
	<p>
	We prove that any extended formulation that approximates the matching polytope on \(n\)-vertex graphs up to a factor of \((1+\epsilon)\) for any \(\frac2n \le \epsilon \le 1\) must have at least \({n} \choose {{\alpha}/{\epsilon}}\) defining inequalities where \(0<\alpha<1\) is an absolute constant. This is tight as exhibited by the \((1+\epsilon)\) approximating linear program obtained by dropping the odd set constraints of size larger than \(({1+\epsilon})/{\epsilon}\) from the description of the matching polytope. Previously, a tight lower bound of \(2^{\Omega(n)}\) was only known for \(\epsilon = O\left(\frac{1}{n}\right)\) [Rothvoss, STOC '14; Braun and Pokutta, IEEE Trans. Information Theory '15] whereas for \(\frac2n \le \epsilon \le 1\), the best lower bound was \(2^{\Omega\left({1}/{\epsilon}\right)}\) [Rothvoss, STOC '14]. The key new ingredient in our proof is a close connection to the non-negative rank of a lopsided version of the unique disjointness matrix.  
	</p>

</div>
<noscript>
	<div class="nsabstract">
<p>
	We prove that any linear program that approximates the matching polytope on \(n\)-vertex graphs up to a factor of \((1+\epsilon)\) for any \(\frac2n \le \epsilon \le 1\) must have at least \({n} \choose {{\alpha}/{\epsilon}}\) inequalities where \(0<\alpha<1\) is an absolute constant. This is tight as exhibited by the \((1+\epsilon)\) approximating linear program obtained by dropping the odd set constraints of size larger than \(({1+\epsilon})/{\epsilon}\) from the description of the matching polytope. Previously, a tight lower bound of \(2^{\Omega(n)}\) was only known for \(\epsilon = O\left(\frac{1}{n}\right)\) [Rothvoss, STOC '14; Braun and Pokutta, IEEE Trans. Information Theory '15] whereas for \(\frac2n \le \epsilon \le 1\), the best lower bound was \(2^{\Omega\left({1}/{\epsilon}\right)}\) [Rothvoss, STOC '14]. The key new ingredient in our proof is a close connection to the non-negative rank of a lopsided version of the unique disjointness matrix.  
</p>
</div></noscript>

<br>



<li>
<span class="papertitle">A Direct-sum Theorem for Read-Once Branching Programs</span><br>
<a href="http://www.cs.washington.edu/homes/anuprao/">Anup Rao</a> and Makrand Sinha<br>
In Proceedings of the 20th International Workshop on Randomization and Computation <strong>(RANDOM'16)</strong></li>
[<a href="./papers/streaming.pdf">pdf</a>] <a href="#" onclick="toggle('stream');return false;" class="plus" id="stream-plus">[Abstract +]</a> <div id="stream" class="abstract"> 
<p>
We study a direct-sum question for read-once branching programs. If \(M(f)\) denotes the minimum average memory required to compute a function \(f(x_1,x_2, \dotsc, x_n)\)  how much memory is required to compute \(f\) on \(k\) independent inputs that arrive in parallel? We show that when the inputs (updates) are sampled independently from some domain \(\mathcal{X}\) and \(M(f) = \Omega(n)\), then computing the value of \(f\) on \(k\) streams requires average memory at least \(\Omega\left(k \cdot \frac{M(f)}{n}\right)\).
<br>

Our results are obtained by defining new ways to measure the information complexity of read-once branching programs. We define two such measures: the <em>transitional</em> and <em>cumulative</em> information content. We prove that any read-once branching program with transitional information content \(\mathtt{I}\) can be simulated using average memory \(\mathcal{O}(n(\mathtt{I}+1))\). On the other hand, if every read-once branching program with cumulative information content \(\mathtt{I}\) can be simulated with average memory \(\mathcal{O}(\mathtt{I}+1)\), then computing \(f\) on \(k\) inputs requires average memory at least \(\Omega(k \cdot (M(f)-1))\). 
</p>

</div>
<noscript>
	<div class="nsabstract">
<p>
We study a direct-sum question for read-once branching programs. If \(M(f)\) denotes the minimum average memory required to compute a function \(f(x_1,x_2, \dotsc, x_n)\)  how much memory is required to compute \(f\) on \(k\) independent inputs that arrive in parallel? We show that when the inputs (updates) are sampled independently from some domain \(\mathcal{X}\) and \(M(f) = \Omega(n)\), then computing the value of \(f\) on \(k\) streams requires average memory at least \(\Omega\left(k \cdot \frac{M(f)}{n}\right)\).
<br>

Our results are obtained by defining new ways to measure the information complexity of read-once branching programs. We define two such measures: the <em>transitional</em> and <em>cumulative</em> information content. We prove that any read-once branching program with transitional information content \(\mathtt{I}\) can be simulated using average memory \(\mathcal{O}(n(\mathtt{I}+1))\). On the other hand, if every read-once branching program with cumulative information content \(\mathtt{I}\) can be simulated with average memory \(\mathcal{O}(\mathtt{I}+1)\), then computing \(f\) on \(k\) inputs requires average memory at least \(\Omega(k \cdot (M(f)-1))\). 
</p>
</div></noscript>

<br>

<li>
<span class="papertitle">Fooling Pairs in Randomized Communication Complexity</span><br>
<a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, Makrand Sinha and <a href="http://tx.technion.ac.il/~yehuday/">Amir Yehudayoff</a><br>
23rd International Colloquium on Structural Information and Communication Complexity <strong>(SIROCCO'16)</strong></li>
[<a href="http://eccc.hpi-web.de/report/2014/022/">ECCC</a>] <a href="#" onclick="toggle('foolingSets');return false;" class="plus" id="foolingSets-plus">[Abstract +]</a> <div id="foolingSets" class="abstract"> 
	<p>
	Fooling pairs are one of the standard methods for proving lower
bounds for deterministic two-player communication complexity.
We study fooling pairs in the context of randomized communication complexity.
We show that every fooling pair induces far away distributions
on transcripts of private-coin protocols.
We then conclude that the private-coin randomized \(\varepsilon\)-error
communication complexity of a function \(f\) with a fooling set
\(\mathcal{S}\) is at least order \(\log \frac{\log |\mathcal{S}|}{\varepsilon}\).
This is tight, for example, for the equality 
and greater-than functions.
</p>

</div>
<noscript>
	<div class="nsabstract">
			<p>
	Fooling pairs are one of the standard methods for proving lower
bounds for deterministic two-player communication complexity.
We study fooling pairs in the context of randomized communication complexity.
We show that every fooling pair induces far away distributions
on transcripts of private-coin protocols.
We then conclude that the private-coin randomized \(\varepsilon\)-error
communication complexity of a function \(f\) with a fooling set
\(\mathcal{S}\) is at least order \(\log \frac{\log |\mathcal{S}|}{\varepsilon).
This is tight, for example, for the equality 
and greater-than functions.
</p>
</div></noscript>

<br>

<li>
<span class="papertitle">On the Communication Complexity of Greater-Than</span><br>
<a href="https://homes.cs.washington.edu/~sivanr/">Sivaramakrishnan Natarajan Ramamoorthy</a> and Makrand Sinha<br>
In Proceedings of the 53rd Annual Allerton Conference on Communication, Control and Computing (<strong>Allerton '15</strong>)</li>
[<a href="./papers/greaterthan.pdf">pdf</a>] <a href="#" onclick="toggle('greaterthan');return false;" class="plus" id="greaterthan-plus">[Abstract +]</a> <div id="greaterthan" class="abstract"> 
	<p>
We give a simple information theoretic proof that the public-coin randomized communication
complexity of the greater-than function is \(\Omega(\log n)\) for bit-strings of length \(n\).
	</p>

</div>
<noscript>
	<div class="nsabstract">
<p>
We give a simple information theoretic proof that the public-coin randomized communication
complexity of the greater-than function is \(\Omega(\log n)\) for bit-strings of length \(n\).
</p>
</div></noscript>

<br>




<li>
<span class="papertitle">Constructing a Pseudorandom Generator Requires an Almost Linear Number of Calls</span><br>
Thomas Holenstein and Makrand Sinha<br>
In proceedings of <em>IEEE 53rd Annual Symposium on Foundations of Computer Science<strong> (FOCS '12)</strong>, p. 698-707, 2012</em></li>
[<a href="http://arxiv.org/abs/1205.4576">arXiv</a>] <a href="#" onclick="toggle('prg');return false;" class="plus" id="prg-plus">[Abstract +]</a> <div id="prg" class="abstract"> 
<p>
	We show that a black-box construction of a pseudorandom generator from a one-way function needs to make \(\Omega(n/log(n))\) calls to the underlying one-way function. The bound even holds if the one-way function is guaranteed to be regular. In this case it matches the best known construction due to Goldreich, Krawczyk, and Luby (SIAM J. Comp. 22, 1993), which uses \(\mathcal{O}(n/log(n))\) calls. 
</p>

</div>
<noscript>
	<div class="nsabstract">

<p>
	We show that a black-box construction of a pseudorandom generator from a one-way function needs to make \(\Omega(n/log(n))\) calls to the underlying one-way function. The bound even holds if the one-way function is guaranteed to be regular. In this case it matches the best known construction due to Goldreich, Krawczyk, and Luby (SIAM J. Comp. 22, 1993), which uses \(\mathcal{O}(n/log(n))\) calls. 
</p>
</div></noscript>

<br>

<li>
<span class="papertitle">Vertices of Degree \(k\) in Random Unlabeled Trees</span><br>
<a href="http://www.mathematik.uni-muenchen.de/~kpanagio/">Konstantinos Panagiotou</a> and Makrand Sinha<br>
Preliminary version in proceedings of the <em>European Conference on Combinatorics, Graph Theory and Applications (<strong>EuroComb '09</strong>), Electronic Notes in Discrete Mathematics, Volume 34, p. 41-45.</em><br>
	Full version appeared in <em><strong>Journal of Graph Theory</strong></em>, Volume 69, Issue 2, p. 114-130, February 2012.</li>
[<a href="./papers/deg-seq-trees.pdf">pdf</a>] <a href="#" onclick="toggle('degTrees');return false;" class="plus" id="degTrees-plus">[Abstract +]</a> <div id="degTrees" class="abstract"> 
<p>Let \(\mathcal{H}_n\) be the class of unlabeled trees with \(n\) vertices, and denote by \(\mathcal{H}_n\) a tree that is drawn uniformly at random from this set. The asymptotic behavior of the random variable \(\deg_k(\mathcal{H}_n)\) that counts vertices of degree \(k\) in \(\mathcal{H}_n\) was studied, among others, by Drmota and Gittenberger, who showed that this quantity satisfies a central limit theorem. This result provides a very precise characterization of the ``central region'' of the distribution, but does not give any non-trivial information about its tails.
<br>
<br>
In this work we study further the number of vertices of degree \(k\) in \(\mathcal{H}_n\). In particular, for \(k = \mathcal{O}\left(\sqrt{\frac{\log n}{\log\log n}}\right)\) we show exponential-type bounds for the probability that \(\deg_k(\mathcal{H}_n)\) deviates from its expectation. On the technical side, our proofs are based on the analysis of a randomized algorithm that generates unlabeled trees in the so-called <em>Boltzmann model</em>. The analysis of such algorithms is quite well-understood for classes of <em>labeled</em> graphs, see e.g. the work by Bernasconi, the first author, and Steger. Comparable algorithms for unlabeled classes are unfortunately much more complex. We demonstrate in this work that they can be analyzed very precisely for classes of
<em>unlabeled</em> graphs as well.
</p>

</div>
<noscript>
<div class="nsabstract">
<p>Let \(\mathcal{H}_n\) be the class of unlabeled trees with \(n\) vertices, and denote by \(\mathcal{H}_n\) a tree that is drawn uniformly at random from this set. The asymptotic behavior of the random variable \(\deg_k(\mathcal{H}_n)\) that counts vertices of degree \(k\) in \(\mathcal{H}_n\) was studied, among others, by Drmota and Gittenberger, who showed that this quantity satisfies a central limit theorem. This result provides a very precise characterization of the ``central region'' of the distribution, but does not give any non-trivial information about its tails.
<br>
<br>
In this work we study further the number of vertices of degree \(k\) in \(\mathcal{H}_n\). In particular, for \(k = \mathcal{O}((\frac{\log n}{\log\log n})^{1/2})\) we show exponential-type bounds for the probability that \(\deg_k(\mathcal{H}_n)\) deviates from its expectation. On the technical side, our proofs are based on the analysis of a randomized algorithm that generates unlabeled trees in the so-called <em>Boltzmann model</em>. The analysis of such algorithms is quite well-understood for classes of <em>labeled</em> graphs, see e.g. the work by Bernasconi, the first author, and Steger. Comparable algorithms for unlabeled classes are unfortunately much more complex. We demonstrate in this work that they can be analyzed very precisely for classes of
<em>unlabeled</em> graphs as well.	
</div></noscript>

<br>
<br>
<br>


</ul>

<br>
<br>
<br>

</div>
</div>

</body></html>

